{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log,exp\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import logisticRegression_functions as lg\n",
    "import itertools\n",
    "import sklearn.metrics as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainlogisticR(xMatrix,yvector):\n",
    "    m = len(xMatrix)\n",
    "    theta_list = [] #stores the list of parameters for the logistic models\n",
    "    for i in range(0,3):\n",
    "        theta = np.ones((m,1))\n",
    "        df = dcostfunction(xMatrix,yvector[i],theta)\n",
    "        itercount = 0\n",
    "        while itercount < 500:\n",
    "            #updating all all theta simultaneously\n",
    "            theta = theta - (0.3)*df\n",
    "            itercount += 1\n",
    "            df = dcostfunction(xMatrix, yvector[i], theta)\n",
    "        theta_list.append(theta)\n",
    "    return theta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costfunction(xvector,yvector,theta):\n",
    "    fx = 0\n",
    "    for i in xvector:\n",
    "        fx = fx + yvector[i]*log(hypothesisfunction(theta,xvector[i]),2)+(1-yvector[i])*log(1-hypothesisfunction(theta,xvector[i]))\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcostfunction(xMatrix,curry,theta): # derivative of the cost function\n",
    "    df = np.zeros((len(xMatrix),1))\n",
    "    for i in range(0,3):\n",
    "        currX = xMatrix[:,i]\n",
    "        df = df + (hypothesisfunction(theta,xMatrix[:,i]) - curry[i])*np.transpose([currX])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesisfunction(theta,xi): # this is the hypothesis function\n",
    "    a = -1*np.dot(np.transpose(theta),xi)\n",
    "    hypothesis = 1/(1+exp(a)) #logistic equation\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatematrix(counters,vocab): #creates matrix for training\n",
    "    xMatrix = np.ones((len(vocab)+1,len(counters)))\n",
    "    iteration = 0\n",
    "    for x in counters:\n",
    "        temp_counter = x[1]\n",
    "        for r in range(1, len(vocab)+1):\n",
    "            xMatrix[r][iteration] = temp_counter.get(vocab[r-1], 0)\n",
    "        iteration = iteration + 1\n",
    "    return xMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_test,y_pred,arr_label):\n",
    "    confusion = sk.confusion_matrix(y_test,y_pred,labels=[k for k in arr_label])\n",
    "    print(confusion)\n",
    "    plt.imshow(confusion, interpolation='nearest',cmap=plt.cm.Blues)\n",
    "    tick_marks = np.arange(confusion.shape[1])\n",
    "    plt.xticks(tick_marks)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels([k for k in arr_label])\n",
    "    plt.yticks(tick_marks)\n",
    "    ax.set_yticklabels([k for k in arr_label])\n",
    "    thresh = confusion.max() / 2.\n",
    "    for i, j in itertools.product(range(confusion.shape[0]), range(confusion.shape[1])):\n",
    "        plt.text(j, i, format(confusion[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if confusion[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.ylabel(\"True Class\")\n",
    "\n",
    "    diag = [confusion[i][i] for i in range(len(confusion))]\n",
    "    accuracy=(sum(list(diag))/len(y_test))*100\n",
    "    print(\"Accuracy:\"+str(accuracy)+\" %\") # this outputs the accuracy of the model\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logisticAlg(X_test,vocab1,theta_list,arr_label):\n",
    "    y_predict = [] # stores the predictions\n",
    "    for i in range(0,len(X_test)):\n",
    "        currX = X_test[i]\n",
    "        currXencode = np.zeros((len(vocab1)+1,1))\n",
    "        currXencode[0] = 1\n",
    "        for k in range(0,len(vocab1)):\n",
    "            if vocab1[k] in currX:\n",
    "                currXencode[k+1] = 1\n",
    "        arr_prob = [] #stores the probabilities outputed by model\n",
    "        for k in theta_list:\n",
    "            temp_val = lg.hypothesisfunction(k,currXencode)\n",
    "            arr_prob.append(temp_val)\n",
    "        index = arr_prob.index(max(arr_prob)) #this finds the index of the largest probability in the arr_prob\n",
    "        y_predict.append(arr_label[index]) #this stores the predicted output of the logistic model.\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open(\"latest.csv\",'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader) #skips first line in csv file\n",
    "        typee = []\n",
    "        med = []\n",
    "        for row in csv_reader:\n",
    "            typee.append(row[1]) #all the types in a list\n",
    "            med.append(row[5]) #all the medical benefits in a list\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(med, typee, test_size = 0.2) #splitting data into trainig and testing\n",
    "    \n",
    "        t = pd.DataFrame(y_train,columns={\"Label\"}) #all the types as Label from 0 to 1881 because trainging data\n",
    "        m = pd.Series(X_train) #all the med benefits from 0 to 1881\n",
    "        t['Features'] = m.values #all med benefits as a feature\n",
    "        categories = np.unique(y_train) #list of different types, hybrid, sativa and indica\n",
    "    \n",
    "        vocab = []\n",
    "        words_list = []\n",
    "        for cat in categories: #for h,s,i do...\n",
    "            temp = t.loc[t[\"Label\"] == cat] #split dataframe by types of h,i,s including corresponding medical benefits\n",
    "            size = len(temp.index) #returns the size of each spilt of h,i,s\n",
    "            words = []\n",
    "            for x in temp.Features:\n",
    "                vocab.append(x)\n",
    "                words.append(x)\n",
    "                words_list.append([cat,vocab,size]) # returs only sativa as a list with all med benefits and size of list *****this is a problem****\n",
    "    \n",
    "        vocab1=np.unique(vocab) #list of unique med benefits\n",
    "    \n",
    "        counters = []\n",
    "        arr_label = []\n",
    "        i = 0\n",
    "    \n",
    "        for cat in words_list:\n",
    "            temp_counter = Counter(cat[1]) #number of each med benefit in each category (only sativa for now)\n",
    "            temp_total = cat[2] #size of each cat\n",
    "            i = i + 1\n",
    "            for key in temp_counter:\n",
    "                temp_counter[key] /=temp_total #prob of each med bene\n",
    "                counters.append([cat[0],temp_counter]) #only for sativa for now, but prob of each bed ben in sativa\n",
    "                arr_label.append(cat[0]) #returns sativa\n",
    "        \n",
    "        yvector = np.identity(3) #creating output category of one vs all logistic regression algorithm\n",
    "    \n",
    "        xMatrix = creatematrix(counters,vocab1) #calling the createXmatrix function\n",
    "        print(\"Data split.\")\n",
    "        print(\"Training Started.\")\n",
    "        theta_list = lg.trainlogisticR(xMatrix,yvector)\n",
    "        print(\"Logistic Model Trained.\")\n",
    "        print(\"Testing Logistic Model\")\n",
    "        y_predict = test_logisticAlg(X_test,vocab1,theta_list,arr_label)\n",
    "        print(\"Printing Confusing Matrix\")\n",
    "        confusion_matrix(y_test,y_predict,arr_label)\n",
    "        print (confusion_matrix)\n",
    "\n",
    "        return 0\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
